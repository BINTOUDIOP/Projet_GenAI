from langchain_openai import ChatOpenAI
import os, re
from dotenv import load_dotenv
from rag_chain import answer as rag_answer
from agent import answer_with_agent

load_dotenv()
llm = ChatOpenAI(model=os.getenv("CHAT_MODEL","gpt-4o-mini"), temperature=0)

# Classifieur trÃ¨s lÃ©ger basÃ© sur des rÃ¨gles + LLM de secours
DOC_HINTS = ["selon", "dans le document", "manuel", "politique", "procÃ©dure", "rapport", "PDF", "docx"]

def simple_route(query: str) -> str:
    q = query.lower()

    # 1) Heuristiques "Agent"
    if re.search(r"\b(\d+\s*[\+\-\*/]\s*\d+|\bmeteo|mÃ©tÃ©o|temperature|tempÃ©rature|recherche sur (le )?web|google|internet)\b", q):
        return "AGENT"

    # 2) Heuristiques "RAG"
    if any(h in q for h in DOC_HINTS):
        return "RAG"

    # 3) LLM fallback trÃ¨s court
    intent = llm.invoke(
        "Tu es un routeur. RÃ©ponds par 'RAG', 'AGENT' ou 'SMALLTALK' uniquement.\n"
        f"Question: {query}"
    ).content.strip().upper()
    if intent not in {"RAG","AGENT","SMALLTALK"}:
        intent = "SMALLTALK"
    return intent

def answer(query: str) -> str:
    mode = simple_route(query)
    if mode == "RAG":
        return rag_answer(query)
    if mode == "AGENT":
        return answer_with_agent(query)
    # SMALLTALK
    return "Bonjour ! Comment puis-je tâ€™aider ? ðŸ˜Š" if len(query.split())<=2 else \
           "Dâ€™accord ! Dis-mâ€™en un peu plus et je mâ€™adapte."